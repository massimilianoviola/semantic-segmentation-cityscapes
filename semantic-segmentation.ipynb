{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"pip install -U -q git+https://github.com/jlcsilva/segmentation_models.pytorch","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nfrom torch.utils.data import DataLoader\nimport torchvision\nimport segmentation_models_pytorch as smp\nfrom segmentation_models_pytorch.encoders import get_preprocessing_fn\nimport cv2\nimport numpy as np\nimport albumentations as A\nimport matplotlib.pyplot as plt","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cv2.setNumThreads(0)\ncv2.ocl.setUseOpenCL(False)\n\n\nclass CityscapesDataset(torchvision.datasets.Cityscapes):\n    def __init__(self, *args, **kwargs):\n        super().__init__(*args, **kwargs, target_type=\"semantic\")\n        self.semantic_target_type_index = [i for i, t in enumerate(self.target_type) if t == \"semantic\"][0]\n        self.colormap = self._generate_colormap()\n\n    def _generate_colormap(self):\n        colormap = {}\n        for class_ in self.classes:\n            if class_.train_id in (-1, 255):\n                continue\n            colormap[class_.train_id] = class_.id\n        return colormap\n\n    def _convert_to_segmentation_mask(self, mask):\n        height, width = mask.shape[:2]\n        segmentation_mask = np.zeros((height, width, len(self.colormap)), dtype=np.float32)\n        for label_index, label in self.colormap.items():\n            segmentation_mask[:, :, label_index] = (mask == label).astype(float)\n        return segmentation_mask\n\n    def to_color_mask(self, segmentation_mask):\n        height, width = segmentation_mask.shape[-2:]\n        color_mask = np.zeros((height, width, 3), dtype=np.uint8)\n        flattened = np.argmax(segmentation_mask, axis=0)\n        for label_index, label in self.colormap.items():\n            color_mask[flattened == label_index] = self.classes[label].color\n        return color_mask    \n    \n    def __getitem__(self, index):\n        image = cv2.imread(self.images[index])\n        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n        mask = cv2.imread(self.targets[index][self.semantic_target_type_index], cv2.IMREAD_UNCHANGED)\n\n        mask = self._convert_to_segmentation_mask(mask)\n\n        if self.transform is not None:\n            transformed = self.transform(image=image, mask=mask)\n            image = transformed[\"image\"]\n            mask = transformed[\"mask\"]\n\n        return image, mask","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = smp.Unet(\n    encoder_name=\"efficientnet-b0\",\n    encoder_weights=\"imagenet\",\n    in_channels=3,\n    classes=19\n)\n\npreprocess_input = get_preprocessing_fn(\"efficientnet-b0\", pretrained=\"imagenet\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def to_tensor(x, **kwargs):\n    return x.transpose(2, 0, 1).astype('float32')\n\n\ndef get_preprocessing(preprocessing_fn):\n    _transform = [\n        A.Lambda(name=\"image_preprocessing\", image=preprocessing_fn),\n        A.Lambda(name=\"to_tensor\", image=to_tensor, mask=to_tensor),\n    ]\n    return A.Compose(_transform)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"transform = A.Compose([\n    A.CenterCrop(256, 256),\n    get_preprocessing(preprocess_input)\n])\n\ntrain_dataset = CityscapesDataset(\"../input/cityscapes/cityscapes\", \n                                  split=\"train\", mode=\"fine\", transform=transform)\n\nvalid_dataset = CityscapesDataset(\"../input/cityscapes/cityscapes\", \n                                  split=\"val\", mode=\"fine\", transform=transform)\n\nimg, smnt = train_dataset[0]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"img.shape, smnt.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for i in range(3):\n    _, mask = train_dataset[i]\n    plt.imshow(train_dataset.to_color_mask(mask))\n    plt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True, num_workers=2)\nvalid_loader = DataLoader(valid_dataset, batch_size=1, shuffle=False, num_workers=2)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"loss = smp.utils.losses.DiceLoss()\nmetrics = [\n    smp.utils.metrics.IoU(threshold=0.5),\n]\n\noptimizer = torch.optim.Adam([ \n    dict(params=model.parameters(), lr=0.001),\n])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n\ntrain_epoch = smp.utils.train.TrainEpoch(\n    model, \n    loss=loss, \n    metrics=metrics, \n    optimizer=optimizer,\n    device=device,\n    verbose=True,\n)\n\nvalid_epoch = smp.utils.train.ValidEpoch(\n    model, \n    loss=loss, \n    metrics=metrics, \n    device=device,\n    verbose=True,\n)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"max_score = 0\n\nfor i in range(0, 1):\n    \n    print('\\nEpoch: {}'.format(i))\n    train_logs = train_epoch.run(train_loader)\n    valid_logs = valid_epoch.run(valid_loader)\n    \n    # do something (save model, change lr, etc.)\n    if max_score < valid_logs['iou_score']:\n        max_score = valid_logs['iou_score']\n        torch.save(model, './best_model.pth')\n        print('Model saved!')","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}