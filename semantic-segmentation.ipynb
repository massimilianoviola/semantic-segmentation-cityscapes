{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"pip install -Uq segmentation-models-pytorch","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nfrom torch.utils.data import DataLoader\nimport torchvision\nimport segmentation_models_pytorch as smp\nfrom segmentation_models_pytorch.encoders import get_preprocessing_fn\nimport cv2\nimport numpy as np\nimport albumentations as A\nimport matplotlib.pyplot as plt","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cv2.setNumThreads(0)\ncv2.ocl.setUseOpenCL(False)\n\n\nclass CityscapesDataset(torchvision.datasets.Cityscapes):\n    def __init__(self, *args, **kwargs):\n        super().__init__(*args, **kwargs, target_type=\"semantic\")\n        self.semantic_target_type_index = [i for i, t in enumerate(self.target_type) if t == \"semantic\"][0]\n        self.colormap = self._generate_colormap()\n\n    def _generate_colormap(self):\n        colormap = {}\n        for class_ in self.classes:\n            if class_.train_id in (-1, 255):\n                continue\n            colormap[class_.train_id] = class_.id\n        return colormap\n\n    def _convert_to_segmentation_mask(self, mask):\n        height, width = mask.shape[:2]\n        segmentation_mask = np.full((height, width), len(self.colormap))\n        for label_index, label in self.colormap.items():\n            segmentation_mask[mask == label] = label_index\n        return segmentation_mask\n\n    def to_color_mask(self, segmentation_mask):\n        height, width = segmentation_mask.shape[-2:]\n        color_mask = np.zeros((height, width, 3), dtype=np.uint8)\n        for label_index, label in self.colormap.items():\n            color_mask[segmentation_mask == label_index] = self.classes[label].color\n        return color_mask    \n    \n    def __getitem__(self, index):\n        image = cv2.imread(self.images[index])\n        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n        mask = cv2.imread(self.targets[index][self.semantic_target_type_index], cv2.IMREAD_UNCHANGED)\n\n        mask = self._convert_to_segmentation_mask(mask)\n\n        if self.transform is not None:\n            transformed = self.transform(image=image, mask=mask)\n            image = transformed[\"image\"]\n            mask = transformed[\"mask\"]\n\n        return image, mask","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = smp.Unet(\n    encoder_name=\"efficientnet-b0\",\n    encoder_weights=\"imagenet\",\n    in_channels=3,\n    classes=20\n)\n\npreprocess_input = get_preprocessing_fn(\"efficientnet-b0\", pretrained=\"imagenet\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def to_tensor(x, **kwargs):\n    return x.transpose(2, 0, 1).astype('float32')\n\n\ndef get_preprocessing(preprocessing_fn):\n    _transform = [\n        A.Lambda(name=\"image_preprocessing\", image=preprocessing_fn),\n        A.Lambda(name=\"to_tensor\", image=to_tensor),\n    ]\n    return A.Compose(_transform)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"transform = A.Compose([\n    A.RandomCrop(384, 384),\n    get_preprocessing(preprocess_input)\n])\n\ntrain_dataset = CityscapesDataset(\"../input/cityscapes/cityscapes\", \n                                  split=\"train\", mode=\"fine\", transform=transform)\n\nvalid_dataset = CityscapesDataset(\"../input/cityscapes/cityscapes\", \n                                  split=\"val\", mode=\"fine\", transform=transform)\n\nimg, smnt = train_dataset[1]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for i in range(3):\n    _, mask = train_dataset[i]\n    plt.imshow(train_dataset.to_color_mask(mask))\n    plt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True, num_workers=2)\nvalid_loader = DataLoader(valid_dataset, batch_size=1, shuffle=False, num_workers=2)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"loss = nn.CrossEntropyLoss()\nloss.__name__ = 'ce_loss'\n\nmetrics = []\n\noptimizer = torch.optim.Adam([ \n    dict(params=model.parameters(), lr=0.001),\n])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n\ntrain_epoch = smp.utils.train.TrainEpoch(\n    model, \n    loss=loss, \n    metrics=metrics, \n    optimizer=optimizer,\n    device=device,\n    verbose=True,\n)\n\nvalid_epoch = smp.utils.train.ValidEpoch(\n    model, \n    loss=loss, \n    metrics=metrics, \n    device=device,\n    verbose=True,\n)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for i in range(0, 3):\n    print('\\nEpoch: {}'.format(i))\n    train_logs = train_epoch.run(train_loader)\n    valid_logs = valid_epoch.run(valid_loader)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"img, smnt = next(iter(valid_loader))\npred = model(img.to(device))\n\ntp, fp, fn, tn = smp.metrics.get_stats(pred.argmax(axis=1), smnt.to(device), mode='multiclass', num_classes=19, ignore_index=19)\nsmp.metrics.functional.iou_score(tp, fp, fn, tn, reduction='micro-imagewise')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"flattened = torch.argmax(pred, axis=1).cpu().numpy()[0]\nplt.imshow(valid_dataset.to_color_mask(flattened))\nplt.show()\nplt.imshow(valid_dataset.to_color_mask(smnt.cpu().numpy()[0]))\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}